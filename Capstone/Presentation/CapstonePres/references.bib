
@misc{wang_review_2022,
	title = {A {Review} on {Graph} {Neural} {Network} {Methods} in {Financial} {Applications}},
	url = {http://arxiv.org/abs/2111.15367},
	doi = {10.48550/arXiv.2111.15367},
	abstract = {With multiple components and relations, financial data are often presented as graph data, since it could represent both the individual features and the complicated relations. Due to the complexity and volatility of the financial market, the graph constructed on the financial data is often heterogeneous or time-varying, which imposes challenges on modeling technology. Among the graph modeling technologies, graph neural network (GNN) models are able to handle the complex graph structure and achieve great performance and thus could be used to solve financial tasks. In this work, we provide a comprehensive review of GNN models in recent financial context. We first categorize the commonly-used financial graphs and summarize the feature processing step for each node. Then we summarize the GNN methodology for each graph type, application in each area, and propose some potential research areas.},
	urldate = {2025-09-03},
	publisher = {arXiv},
	author = {Wang, Jianian and Zhang, Sheng and Xiao, Yanghua and Song, Rui},
	month = apr,
	year = {2022},
	note = {arXiv:2111.15367 [q-fin]},
	keywords = {Computer Science - Machine Learning, Quantitative Finance - Statistical Finance, Statistics - Applications},
	file = {Full Text PDF:/home/sspiegel/Zotero/storage/GMD2E7A7/Wang et al. - 2022 - A Review on Graph Neural Network Methods in Financial Applications.pdf:application/pdf;Snapshot:/home/sspiegel/Zotero/storage/4WX6JB24/2111.html:text/html},
}

@misc{kong_generative_2023,
	title = {Generative {Models} for {3D} {Point} {Clouds}},
	url = {http://arxiv.org/abs/2302.13408},
	doi = {10.48550/arXiv.2302.13408},
	abstract = {Point clouds are rich geometric data structures, where their three dimensional structure offers an excellent domain for understanding the representation learning and generative modeling in 3D space. In this work, we aim to improve the performance of point cloud latent-space generative models by experimenting with transformer encoders, latent-space flow models, and autoregressive decoders. We analyze and compare both generation and reconstruction performance of these models on various object types.},
	urldate = {2025-10-11},
	publisher = {arXiv},
	author = {Kong, Lingjie and Rajak, Pankaj and Shakeri, Siamak},
	month = feb,
	year = {2023},
	note = {arXiv:2302.13408 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
	file = {Full Text PDF:/home/sspiegel/Zotero/storage/U3QI4PCX/Kong et al. - 2023 - Generative Models for 3D Point Clouds.pdf:application/pdf;Snapshot:/home/sspiegel/Zotero/storage/DLJKIELP/2302.html:text/html},
}

@misc{kong_generative_2023-1,
	title = {Generative {Models} for {3D} {Point} {Clouds}},
	url = {http://arxiv.org/abs/2302.13408},
	doi = {10.48550/arXiv.2302.13408},
	abstract = {Point clouds are rich geometric data structures, where their three dimensional structure offers an excellent domain for understanding the representation learning and generative modeling in 3D space. In this work, we aim to improve the performance of point cloud latent-space generative models by experimenting with transformer encoders, latent-space flow models, and autoregressive decoders. We analyze and compare both generation and reconstruction performance of these models on various object types.},
	urldate = {2025-10-11},
	publisher = {arXiv},
	author = {Kong, Lingjie and Rajak, Pankaj and Shakeri, Siamak},
	month = feb,
	year = {2023},
	note = {arXiv:2302.13408 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
	file = {Preprint PDF:/home/sspiegel/Zotero/storage/8Q3XRWAK/Kong et al. - 2023 - Generative Models for 3D Point Clouds.pdf:application/pdf;Snapshot:/home/sspiegel/Zotero/storage/CLESAH66/2302.html:text/html},
}

@article{thomas_learning_nodate,
	title = {Learning new representations for {3D} point cloud semantic segmentation},
	language = {en},
	author = {Thomas, Hugues},
	file = {PDF:/home/sspiegel/Zotero/storage/JATS2XGC/Thomas - Learning new representations for 3D point cloud semantic segmentation.pdf:application/pdf},
}

@article{han_whu-urban3d_2024,
	title = {{WHU}-{Urban3D}: {An} urban scene {LiDAR} point cloud dataset for semantic instance segmentation},
	volume = {209},
	issn = {0924-2716},
	shorttitle = {{WHU}-{Urban3D}},
	url = {https://www.sciencedirect.com/science/article/pii/S0924271624000522},
	doi = {10.1016/j.isprsjprs.2024.02.007},
	abstract = {With the rapid advancement of 3D sensors, there is an increasing demand for 3D scene understanding and an increasing number of 3D deep learning algorithms have been proposed. However, a large-scale and richly annotated 3D point cloud dataset is critical to understanding complicated road and urban scenes. Motivated by the need to bridge the gap between the rising demand for 3D urban scene understanding and limited LiDAR point cloud datasets, this paper proposes a richly annotated WHU-Urban3D dataset and an effective method for semantic instance segmentation. WHU-Urban3D stands out from existing datasets due to its distinctive features: (1) extensive coverage of both Airborne Laser Scanning and Mobile Laser Scanning point clouds, along with panoramic images; (2) containing large-scale road and urban scenes in different cities (over 3.2×106m2 area), with richly point-wise semantic instance labels (over 200 million points); (3) inclusion of particular attributes (e.g., reflected intensity, number of returns) in addition to 3D coordinates. This paper also provides the performance of several representative baseline methods and outlines potential future works and challenges for fully exploiting this dataset. The WHU-Urban3D dataset is publicly accessible at https://whu3d.com/.},
	urldate = {2025-10-13},
	journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
	author = {Han, Xu and Liu, Chong and Zhou, Yuzhou and Tan, Kai and Dong, Zhen and Yang, Bisheng},
	month = mar,
	year = {2024},
	keywords = {Machine learning, Point cloud, Semantic instance segmentation, Urban-scale dataset},
	pages = {500--513},
	file = {ScienceDirect Snapshot:/home/sspiegel/Zotero/storage/5WHCA6QZ/S0924271624000522.html:text/html},
}

@article{chakraborty_segmentation_2024,
	title = {Segmentation of {LiDAR} point cloud data in urban areas using adaptive neighborhood selection technique},
	volume = {19},
	issn = {1932-6203},
	url = {https://pmc.ncbi.nlm.nih.gov/articles/PMC11257351/},
	doi = {10.1371/journal.pone.0307138},
	abstract = {Semantic segmentation of urban areas using Light Detection and Ranging (LiDAR) point cloud data is challenging due to the complexity, outliers, and heterogeneous nature of the input point cloud data. The machine learning-based methods for segmenting point clouds suffer from the imprecise computation of the training feature values. The most important factor that influences how precisely the feature values are computed is the neighborhood chosen by each point. This research addresses this issue and proposes a suitable adaptive neighborhood selection approach for individual points by completely considering the complex and heterogeneous nature of the input LiDAR point cloud data. The proposed approach is evaluated on high-density mobile and low-density aerial LiDAR point cloud datasets using the Random Forest machine learning classifier. In the context of performance evaluation, the proposed approach confirms the competitive performance over the state-of-the-art approaches. The computed accuracy and F1-score for the high-density Toronto and low-density Vaihingen datasets are greater than 91\% and 82\%, respectively.},
	number = {7},
	urldate = {2025-10-13},
	journal = {PLOS ONE},
	author = {Chakraborty, Debobrata and Dey, Emon Kumar},
	month = jul,
	year = {2024},
	pmid = {39024214},
	pmcid = {PMC11257351},
	pages = {e0307138},
	file = {Full Text PDF:/home/sspiegel/Zotero/storage/EYATSKS9/Chakraborty and Dey - 2024 - Segmentation of LiDAR point cloud data in urban areas using adaptive neighborhood selection techniqu.pdf:application/pdf},
}

@article{kuprowski_feature_2023,
	title = {Feature {Selection} for {Airbone} {LiDAR} {Point} {Cloud} {Classification}},
	volume = {15},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2072-4292},
	url = {https://www.mdpi.com/2072-4292/15/3/561},
	doi = {10.3390/rs15030561},
	abstract = {The classification of airborne LiDAR data is a prerequisite for many spatial data elaborations and analysis. In the domain of power supply networks, it is of utmost importance to be able to discern at least five classes for further processing—ground, buildings, vegetation, poles, and catenaries. This process is mainly performed manually by domain experts with the use of advanced point cloud manipulation software. The goal of this paper is to find a set of features which would divide space well enough to achieve accurate automatic classification on all relevant classes within the domain, thus reducing manual labor. To tackle this problem, we propose a single multi-class approach to classify all four basic classes (excluding ground) in a power supply domain with single pass-through, using one network. The proposed solution implements random forests and gradient boosting to create a feature-based per-point classifier which achieved an accuracy and F1 score of over 99\% on all tested cases, with the maximum of 99.7\% for accuracy and 99.5\% for F1 score. Moreover, we achieved a maximum of 81.7\% F1 score for the most sparse class. The results show that the proposed set of features for the LiDAR data cloud is effective in power supply line classification.},
	language = {en},
	number = {3},
	urldate = {2025-10-13},
	journal = {Remote Sensing},
	author = {Kuprowski, Mateusz and Drozda, Pawel},
	month = jan,
	year = {2023},
	note = {Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {feature selection, LiDAR, multi-scale neighborhood features, power supply network classification, random forests, XGBoost},
	pages = {561},
	file = {Full Text PDF:/home/sspiegel/Zotero/storage/G8BN6WAV/Kuprowski and Drozda - 2023 - Feature Selection for Airbone LiDAR Point Cloud Classification.pdf:application/pdf},
}

@inproceedings{thomas_semantic_2018,
	address = {Verona},
	title = {Semantic {Classification} of {3D} {Point} {Clouds} with {Multiscale} {Spherical} {Neighborhoods}},
	isbn = {978-1-5386-8425-2},
	url = {https://ieeexplore.ieee.org/document/8490990/},
	doi = {10.1109/3DV.2018.00052},
	abstract = {This paper introduces a new deﬁnition of multiscale neighborhoods in 3D point clouds. This deﬁnition, based on spherical neighborhoods and proportional subsampling, allows the computation of features with a consistent geometrical meaning, which is not the case when using k-nearest neighbors. With an appropriate learning strategy, the proposed features can be used in a random forest to classify 3D points. In this semantic classiﬁcation task, we show that our multiscale features outperform state-of-the-art features using the same experimental conditions. Furthermore, their classiﬁcation power competes with more elaborate classiﬁcation approaches including Deep Learning methods.},
	language = {en},
	urldate = {2025-10-14},
	booktitle = {2018 {International} {Conference} on {3D} {Vision} ({3DV})},
	publisher = {IEEE},
	author = {Thomas, Hugues and Goulette, Francois and Deschaud, Jean-Emmanuel and Marcotegui, Beatriz and LeGall, Yann},
	month = sep,
	year = {2018},
	pages = {390--398},
	file = {PDF:/home/sspiegel/Zotero/storage/2WKC3BHE/Thomas et al. - 2018 - Semantic Classification of 3D Point Clouds with Multiscale Spherical Neighborhoods.pdf:application/pdf},
}

@misc{noauthor_2020_nodate,
	title = {2020 {LiDAR} - {Classified} {LAS}},
	url = {https://opendata.dc.gov/datasets/DCGIS::2020-lidar-classified-las/about},
	abstract = {This data is used for the planning and management of Washington, D.C. by local government agencies.},
	language = {en-us},
	urldate = {2025-10-17},
	file = {Snapshot:/home/sspiegel/Zotero/storage/ZS67RP74/about.html:text/html},
}

@misc{noauthor_kpconv_nodate,
	title = {{KPConv}: {Flexible} and {Deformable} {Convolution} for {Point} {Clouds}},
	shorttitle = {{KPConv}},
	url = {https://ar5iv.labs.arxiv.org/html/1904.08889},
	abstract = {We present Kernel Point Convolution111Project page: https://github.com/HuguesTHOMAS/KPConv (KPConv), a new design of point convolution, i.e. that operates on point clouds without any intermediate representation. The co…},
	language = {en},
	urldate = {2025-10-22},
	journal = {ar5iv},
	file = {Snapshot:/home/sspiegel/Zotero/storage/DIIHWCYN/1904.html:text/html},
}

@inproceedings{tan_toronto-3d_2020,
	address = {Seattle, WA, USA},
	title = {Toronto-{3D}: {A} {Large}-scale {Mobile} {LiDAR} {Dataset} for {Semantic} {Segmentation} of {Urban} {Roadways}},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	isbn = {978-1-7281-9360-1},
	shorttitle = {Toronto-{3D}},
	url = {https://ieeexplore.ieee.org/document/9150609/},
	doi = {10.1109/CVPRW50498.2020.00109},
	abstract = {Semantic segmentation of large-scale outdoor point clouds is essential for urban scene understanding in various applications, especially autonomous driving and urban high-deﬁnition (HD) mapping. With rapid developments of mobile laser scanning (MLS) systems, massive point clouds are available for scene understanding, but publicly accessible large-scale labeled datasets, which are essential for developing learning-based methods, are still limited. This paper introduces Toronto-3D, a large-scale urban outdoor point cloud dataset acquired by a MLS system in Toronto, Canada for semantic segmentation. This dataset covers approximately 1 km of point clouds and consists of about 78.3 million points with 8 labeled object classes. Baseline experiments for semantic segmentation were conducted and the results conﬁrmed the capability of this dataset to train deep learning models effectively. Toronto-3D is released 1 to encourage new research, and the labels will be improved and updated with feedback from the research community.},
	language = {en},
	urldate = {2025-10-24},
	booktitle = {2020 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} {Workshops} ({CVPRW})},
	publisher = {IEEE},
	author = {Tan, Weikai and Qin, Nannan and Ma, Lingfei and Li, Ying and Du, Jing and Cai, Guorong and Yang, Ke and Li, Jonathan},
	month = jun,
	year = {2020},
	pages = {797--806},
	file = {PDF:/home/sspiegel/Zotero/storage/DEYM2XCJ/Tan et al. - 2020 - Toronto-3D A Large-scale Mobile LiDAR Dataset for Semantic Segmentation of Urban Roadways.pdf:application/pdf},
}

@misc{noauthor_illinois_nodate,
	title = {Illinois {Height} {Modernization} ({ILHMP}): {LiDAR} {Data} {\textbar} clearinghouse.isgs.illinois.edu},
	url = {https://clearinghouse.isgs.illinois.edu/data/elevation/illinois-height-modernization-ilhmp},
	urldate = {2025-10-24},
	file = {Illinois Height Modernization (ILHMP)\: LiDAR Data | clearinghouse.isgs.illinois.edu:/home/sspiegel/Zotero/storage/J95SIXG3/illinois-height-modernization-ilhmp.html:text/html},
}

@article{rusu_semantic_2010,
	title = {Semantic {3D} {Object} {Maps} for {Everyday} {Manipulation} in {Human} {Living} {Environments}},
	volume = {24},
	copyright = {http://www.springer.com/tdm},
	issn = {0933-1875, 1610-1987},
	url = {http://link.springer.com/10.1007/s13218-010-0059-6},
	doi = {10.1007/s13218-010-0059-6},
	language = {en},
	number = {4},
	urldate = {2025-10-24},
	journal = {KI - Künstliche Intelligenz},
	author = {Rusu, Radu Bogdan},
	month = nov,
	year = {2010},
	pages = {345--348},
	file = {PDF:/home/sspiegel/Zotero/storage/27TKAHAE/Rusu - 2010 - Semantic 3D Object Maps for Everyday Manipulation in Human Living Environments.pdf:application/pdf},
}

@article{rusu_semantic_2010-1,
	title = {Semantic {3D} {Object} {Maps} for {Everyday} {Manipulation} in {Human} {Living} {Environments}},
	volume = {24},
	issn = {1610-1987},
	url = {https://doi.org/10.1007/s13218-010-0059-6},
	doi = {10.1007/s13218-010-0059-6},
	abstract = {Environment models serve as important resources for an autonomous robot by providing it with the necessary task-relevant information about its habitat. Their use enables robots to perform their tasks more reliably, flexibly, and efficiently. As autonomous robotic platforms get more sophisticated manipulation capabilities, they also need more expressive and comprehensive environment models: for manipulation purposes their models have to include the objects present in the world, together with their position, form, and other aspects, as well as an interpretation of these objects with respect to the robot tasks.},
	language = {en},
	number = {4},
	urldate = {2025-10-24},
	journal = {KI - Künstliche Intelligenz},
	author = {Rusu, Radu Bogdan},
	month = nov,
	year = {2010},
	keywords = {Machine Learning Classifier, Perception Problem, Point Cloud, Robot Hexapod, Robot Operating System},
	pages = {345--348},
}

@article{filin_neighborhood_2005,
	title = {Neighborhood {Systems} for {Airborne} {Laser} {Data}},
	volume = {71},
	doi = {10.14358/PERS.71.6.743},
	abstract = {Analysis of common neighborhood definitions for airborne laser data, triangulation or raster-based, reveals deficiencies in modeling the measured objects. Concepts that originate from 2D data structures are used for modeling complex 3D objects and for handling datasets with different
point densities. Realizing these shortcomings, this paper proposes a new neighborhood system for airborne laser data. Based on laser data characteristics the proposed systems consider, among other features, point density, layered and overhanging structures, and local surface trends. Parameters
for the proposed systems are derived from theoretical and practical observations. The paper demonstrates the type of neighborhood that is established by the proposed systems, and shows that artifacts that are usually created by the common neighborhoods are avoided here, and that structures
within the data that are usually masked are revealed. The paper demonstrates how subsequent applications benefit from the new system. Finally, the estimation of surface normals by the proposed systems is compared to the triangulation; results show a significant improvement in the reliability
and quality of the estimation.},
	number = {6},
	journal = {Photogrammetric Engineering \& Remote Sensing},
	author = {Filin, Sagi and Pfeifer, Norbert},
	month = jun,
	year = {2005},
	pages = {743--755},
	file = {IngentaConnect Full Text PDF:/home/sspiegel/Zotero/storage/KIUU5SAQ/Filin and Pfeifer - 2005 - Neighborhood Systems for Airborne Laser Data.pdf:application/pdf},
}

@article{weinmann_semantic_2015,
	title = {Semantic point cloud interpretation based on optimal neighborhoods, relevant features and efficient classifiers},
	volume = {105},
	issn = {0924-2716},
	url = {https://www.sciencedirect.com/science/article/pii/S0924271615000349},
	doi = {10.1016/j.isprsjprs.2015.01.016},
	abstract = {3D scene analysis in terms of automatically assigning 3D points a respective semantic label has become a topic of great importance in photogrammetry, remote sensing, computer vision and robotics. In this paper, we address the issue of how to increase the distinctiveness of geometric features and select the most relevant ones among these for 3D scene analysis. We present a new, fully automated and versatile framework composed of four components: (i) neighborhood selection, (ii) feature extraction, (iii) feature selection and (iv) classification. For each component, we consider a variety of approaches which allow applicability in terms of simplicity, efficiency and reproducibility, so that end-users can easily apply the different components and do not require expert knowledge in the respective domains. In a detailed evaluation involving 7 neighborhood definitions, 21 geometric features, 7 approaches for feature selection, 10 classifiers and 2 benchmark datasets, we demonstrate that the selection of optimal neighborhoods for individual 3D points significantly improves the results of 3D scene analysis. Additionally, we show that the selection of adequate feature subsets may even further increase the quality of the derived results while significantly reducing both processing time and memory consumption.},
	urldate = {2025-11-05},
	journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
	author = {Weinmann, Martin and Jutzi, Boris and Hinz, Stefan and Mallet, Clément},
	month = jul,
	year = {2015},
	keywords = {Point cloud, 3D scene analysis, Classification, Feature extraction, Feature selection, Neighborhood selection},
	pages = {286--304},
	file = {ScienceDirect Snapshot:/home/sspiegel/Zotero/storage/FZAPWJEB/S0924271615000349.html:text/html},
}

@misc{noauthor_pdf_nodate,
	title = {({PDF}) {Segmentation} of {Planar} {Surfaces} from {Laser} {Scanning} {Data} {Using} the {Magnitude} of {Normal} {Position} {Vector} for {Adaptive} {Neighborhoods}},
	url = {https://www.researchgate.net/publication/291530029_Segmentation_of_Planar_Surfaces_from_Laser_Scanning_Data_Using_the_Magnitude_of_Normal_Position_Vector_for_Adaptive_Neighborhoods?_tp=eyJjb250ZXh0Ijp7ImZpcnN0UGFnZSI6Il9kaXJlY3QiLCJwYWdlIjoiX2RpcmVjdCJ9fQ},
	urldate = {2025-10-30},
}

@article{chakraborty_segmentation_2024-1,
	title = {Segmentation of {LiDAR} point cloud data in urban areas using adaptive neighborhood selection technique},
	volume = {19},
	issn = {1932-6203},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0307138},
	doi = {10.1371/journal.pone.0307138},
	abstract = {Semantic segmentation of urban areas using Light Detection and Ranging (LiDAR) point cloud data is challenging due to the complexity, outliers, and heterogeneous nature of the input point cloud data. The machine learning-based methods for segmenting point clouds suffer from the imprecise computation of the training feature values. The most important factor that influences how precisely the feature values are computed is the neighborhood chosen by each point. This research addresses this issue and proposes a suitable adaptive neighborhood selection approach for individual points by completely considering the complex and heterogeneous nature of the input LiDAR point cloud data. The proposed approach is evaluated on high-density mobile and low-density aerial LiDAR point cloud datasets using the Random Forest machine learning classifier. In the context of performance evaluation, the proposed approach confirms the competitive performance over the state-of-the-art approaches. The computed accuracy and F1-score for the high-density Toronto and low-density Vaihingen datasets are greater than 91\% and 82\%, respectively.},
	language = {en},
	number = {7},
	urldate = {2025-10-30},
	journal = {PLOS ONE},
	author = {Chakraborty, Debobrata and Dey, Emon Kumar},
	month = jul,
	year = {2024},
	note = {Publisher: Public Library of Science},
	keywords = {Machine learning, Curvature, Deep learning, Eigenvalues, Lidar, Neighborhoods, Radii, Urban areas},
	pages = {e0307138},
	file = {Full Text PDF:/home/sspiegel/Zotero/storage/GWX4SRPR/Chakraborty and Dey - 2024 - Segmentation of LiDAR point cloud data in urban areas using adaptive neighborhood selection techniqu.pdf:application/pdf},
}

@article{singer_dales_2021,
	title = {{DALES} {Objects}: {A} {Large} {Scale} {Benchmark} {Dataset} for {Instance} {Segmentation} in {Aerial} {Lidar}},
	volume = {9},
	issn = {2169-3536},
	shorttitle = {{DALES} {Objects}},
	url = {https://ieeexplore.ieee.org/document/9469802},
	doi = {10.1109/ACCESS.2021.3094127},
	abstract = {We present DALES Objects, a large-scale instance segmentation benchmark dataset for aerial lidar. DALES Objects contains close to half a billion hand-labeled points, including semantic and instance segmentation labels. DALES Objects is an extension of the DALES (Varney et al., 2020) dataset, adding additional intensity and instance segmentation annotation. This paper provides an overview of the data collection, preprocessing, hand-labeling strategy, and final data format. We propose relevant evaluation metrics and provide insights into potential challenges when evaluating this benchmark dataset. Finally, we provide information about how researchers can access the dataset for their use at go.udayton.edu/dales3d.},
	urldate = {2025-10-30},
	journal = {IEEE Access},
	author = {Singer, Nina M. and Asari, Vijayan K.},
	year = {2021},
	keywords = {Deep learning, 3D data set, aerial vision, airborne system, ALS, benchmark data, Benchmark testing, data annotation, deep learning, earth scan, instance segmentation, Laser radar, laser scan, lidar, point cloud, semantic segmentation, Semantics, Task analysis, Three-dimensional displays, Vegetation mapping},
	pages = {97495--97504},
	file = {Full Text PDF:/home/sspiegel/Zotero/storage/3FQEJ2WN/Singer and Asari - 2021 - DALES Objects A Large Scale Benchmark Dataset for Instance Segmentation in Aerial Lidar.pdf:application/pdf},
}

@inproceedings{lin_pointacc_2021,
	title = {{PointAcc}: {Efficient} {Point} {Cloud} {Accelerator}},
	shorttitle = {{PointAcc}},
	url = {http://arxiv.org/abs/2110.07600},
	doi = {10.1145/3466752.3480084},
	abstract = {Deep learning on point clouds plays a vital role in a wide range of applications such as autonomous driving and AR/VR. These applications interact with people in real time on edge devices and thus require low latency and low energy. Compared to projecting the point cloud to 2D space, directly processing 3D point cloud yields higher accuracy and lower \#MACs. However, the extremely sparse nature of point cloud poses challenges to hardware acceleration. For example, we need to explicitly determine the nonzero outputs and search for the nonzero neighbors (mapping operation), which is unsupported in existing accelerators. Furthermore, explicit gather and scatter of sparse features are required, resulting in large data movement overhead.},
	language = {en},
	urldate = {2025-10-30},
	booktitle = {{MICRO}-54: 54th {Annual} {IEEE}/{ACM} {International} {Symposium} on {Microarchitecture}},
	author = {Lin, Yujun and Zhang, Zhekai and Tang, Haotian and Wang, Hanrui and Han, Song},
	month = oct,
	year = {2021},
	note = {arXiv:2110.07600 [cs]},
	keywords = {Computer Science - Hardware Architecture},
	pages = {449--461},
	file = {PDF:/home/sspiegel/Zotero/storage/ALLGN7NI/Lin et al. - 2021 - PointAcc Efficient Point Cloud Accelerator.pdf:application/pdf},
}

@misc{roynard_paris-lille-3d_2017,
	title = {Paris-{Lille}-{3D}: a large and high-quality ground truth urban point cloud dataset for automatic segmentation and classification},
	shorttitle = {Paris-{Lille}-{3D}},
	url = {https://arxiv.org/abs/1712.00032v2},
	abstract = {This paper introduces a new Urban Point Cloud Dataset for Automatic Segmentation and Classification acquired by Mobile Laser Scanning (MLS). We describe how the dataset is obtained from acquisition to post-processing and labeling. This dataset can be used to learn classification algorithm, however, given that a great attention has been paid to the split between the different objects, this dataset can also be used to learn the segmentation. The dataset consists of around 2km of MLS point cloud acquired in two cities. The number of points and range of classes make us consider that it can be used to train Deep-Learning methods. Besides we show some results of automatic segmentation and classification. The dataset is available at: http://caor-mines-paristech.fr/fr/paris-lille-3d-dataset/},
	language = {en},
	urldate = {2025-11-11},
	journal = {arXiv.org},
	author = {Roynard, Xavier and Deschaud, Jean-Emmanuel and Goulette, François},
	month = nov,
	year = {2017},
	file = {Full Text PDF:/home/sspiegel/Zotero/storage/PSLETCHL/Roynard et al. - 2017 - Paris-Lille-3D a large and high-quality ground truth urban point cloud dataset for automatic segmen.pdf:application/pdf},
}

@inproceedings{chu_neighbor-vote_2021,
	address = {Virtual Event China},
	title = {Neighbor-{Vote}: {Improving} {Monocular} {3D} {Object} {Detection} through {Neighbor} {Distance} {Voting}},
	isbn = {978-1-4503-8651-7},
	shorttitle = {Neighbor-{Vote}},
	url = {https://dl.acm.org/doi/10.1145/3474085.3475641},
	doi = {10.1145/3474085.3475641},
	language = {en},
	urldate = {2025-11-11},
	booktitle = {Proceedings of the 29th {ACM} {International} {Conference} on {Multimedia}},
	publisher = {ACM},
	author = {Chu, Xiaomeng and Deng, Jiajun and Li, Yao and Yuan, Zhenxun and Zhang, Yanyong and Ji, Jianmin and Zhang, Yu},
	month = oct,
	year = {2021},
	pages = {5239--5247},
}

@article{mohamed_evaluation_2021,
	title = {Evaluation of data subsampling and neighbourhood selection for mobile {LiDAR} data classification},
	volume = {24},
	issn = {1110-9823},
	url = {https://www.sciencedirect.com/science/article/pii/S1110982321000363},
	doi = {10.1016/j.ejrs.2021.04.003},
	abstract = {Road features extraction is essential for autonomous driving vehicles and road maintenance. Mobile Laser Scanning (MLS) systems have proven their capability for dense and accurate LiDAR point cloud data acquisition of road features. Usually, MLS data are received in the format of XYZ coordinates and sometimes with intensity values. Thus, the first step in MLS data processing is point classification, which mainly relays on the geometric distribution of surrounding points. However, processing such huge data is costly and time- consuming. Therefore, in this research, different neighborhood selection methods, including k nearest neighbors, spherical and cylindrical methods are evaluated to reveal the suitable method for MLS data classification. In addition, a data sub-sampling method based on minimum point spacing is applied in order to reduce the processing time. A set of point features, including covariance, moment and height was first extracted based on the three neighborhood selection methods. Random forest classifier was then used to classify a part of the benchmark dataset of Paris–Lille-3D, which belongs to NPM3D Benchmark suite research project. The dataset is divided into three main parts; Lille 1, Lille 2 and Paris. Lille 1 and Lille 2 were used in this research with about 1.5 km longitudinal road and about 98.1 million total number of points. Six scenarios were evaluated; three for the full dataset and three for the sub-sampled dataset using the aforementioned neighborhood selection methods. The results showed that the cylindrical neighborhood selection method achieved the highest classification accuracy of 92.39\% and 90.26\% for the full and sub-sampled datasets, respectively. The data sub-sampling has showed a good performance, whereas the dataset was reduced by about half and processing time was reduced by almost half with close classification accuracy using the cylindrical neighborhood selection method.},
	number = {3, Part 2},
	urldate = {2025-11-11},
	journal = {The Egyptian Journal of Remote Sensing and Space Science},
	author = {Mohamed, Mahmoud and Morsy, Salem and El-Shazly, Adel},
	month = dec,
	year = {2021},
	keywords = {Classification, Neighborhood selection, Mobile LiDAR scanning, Random forest, Sub-sampling},
	pages = {799--804},
	file = {ScienceDirect Full Text PDF:/home/sspiegel/Zotero/storage/BFRURUJW/Mohamed et al. - 2021 - Evaluation of data subsampling and neighbourhood selection for mobile LiDAR data classification.pdf:application/pdf;ScienceDirect Snapshot:/home/sspiegel/Zotero/storage/NG4YCYG8/S1110982321000363.html:text/html},
}

@inproceedings{chu_neighbor-vote_2021-1,
	address = {Virtual Event China},
	title = {Neighbor-{Vote}: {Improving} {Monocular} {3D} {Object} {Detection} through {Neighbor} {Distance} {Voting}},
	isbn = {978-1-4503-8651-7},
	shorttitle = {Neighbor-{Vote}},
	url = {https://dl.acm.org/doi/10.1145/3474085.3475641},
	doi = {10.1145/3474085.3475641},
	language = {en},
	urldate = {2025-11-11},
	booktitle = {Proceedings of the 29th {ACM} {International} {Conference} on {Multimedia}},
	publisher = {ACM},
	author = {Chu, Xiaomeng and Deng, Jiajun and Li, Yao and Yuan, Zhenxun and Zhang, Yanyong and Ji, Jianmin and Zhang, Yu},
	month = oct,
	year = {2021},
	pages = {5239--5247},
}

@misc{thomas_kpconv_2019,
	title = {{KPConv}: {Flexible} and {Deformable} {Convolution} for {Point} {Clouds}},
	shorttitle = {{KPConv}},
	url = {http://arxiv.org/abs/1904.08889},
	doi = {10.48550/arXiv.1904.08889},
	abstract = {We present Kernel Point Convolution (KPConv), a new design of point convolution, i.e. that operates on point clouds without any intermediate representation. The convolution weights of KPConv are located in Euclidean space by kernel points, and applied to the input points close to them. Its capacity to use any number of kernel points gives KPConv more flexibility than fixed grid convolutions. Furthermore, these locations are continuous in space and can be learned by the network. Therefore, KPConv can be extended to deformable convolutions that learn to adapt kernel points to local geometry. Thanks to a regular subsampling strategy, KPConv is also efficient and robust to varying densities. Whether they use deformable KPConv for complex tasks, or rigid KPconv for simpler tasks, our networks outperform state-of-the-art classification and segmentation approaches on several datasets. We also offer ablation studies and visualizations to provide understanding of what has been learned by KPConv and to validate the descriptive power of deformable KPConv.},
	urldate = {2025-11-12},
	publisher = {arXiv},
	author = {Thomas, Hugues and Qi, Charles R. and Deschaud, Jean-Emmanuel and Marcotegui, Beatriz and Goulette, François and Guibas, Leonidas J.},
	month = aug,
	year = {2019},
	note = {arXiv:1904.08889 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {Full Text PDF:/home/sspiegel/Zotero/storage/PHE8N7PS/Thomas et al. - 2019 - KPConv Flexible and Deformable Convolution for Point Clouds.pdf:application/pdf;Snapshot:/home/sspiegel/Zotero/storage/ERXP2Y8C/1904.html:text/html},
}

@misc{hu_randla-net_2020,
	title = {{RandLA}-{Net}: {Efficient} {Semantic} {Segmentation} of {Large}-{Scale} {Point} {Clouds}},
	shorttitle = {{RandLA}-{Net}},
	url = {http://arxiv.org/abs/1911.11236},
	doi = {10.48550/arXiv.1911.11236},
	abstract = {We study the problem of efficient semantic segmentation for large-scale 3D point clouds. By relying on expensive sampling techniques or computationally heavy pre/post-processing steps, most existing approaches are only able to be trained and operate over small-scale point clouds. In this paper, we introduce RandLA-Net, an efficient and lightweight neural architecture to directly infer per-point semantics for large-scale point clouds. The key to our approach is to use random point sampling instead of more complex point selection approaches. Although remarkably computation and memory efficient, random sampling can discard key features by chance. To overcome this, we introduce a novel local feature aggregation module to progressively increase the receptive field for each 3D point, thereby effectively preserving geometric details. Extensive experiments show that our RandLA-Net can process 1 million points in a single pass with up to 200X faster than existing approaches. Moreover, our RandLA-Net clearly surpasses state-of-the-art approaches for semantic segmentation on two large-scale benchmarks Semantic3D and SemanticKITTI.},
	urldate = {2025-11-12},
	publisher = {arXiv},
	author = {Hu, Qingyong and Yang, Bo and Xie, Linhai and Rosa, Stefano and Guo, Yulan and Wang, Zhihua and Trigoni, Niki and Markham, Andrew},
	month = may,
	year = {2020},
	note = {arXiv:1911.11236 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Electrical Engineering and Systems Science - Image and Video Processing},
	file = {Snapshot:/home/sspiegel/Zotero/storage/BW6FQWIJ/1911.html:text/html},
}
