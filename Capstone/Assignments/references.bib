
@misc{noauthor_notitle_nodate,
}

@misc{boutet_guides_nodate,
	title = {Guides de recherche · {Research} guides: {How} to {Use} {Zotero}: {Install} {Zotero} browser connector},
	copyright = {Copyright University of Ottawa 2024},
	shorttitle = {Guides de recherche · {Research} guides},
	url = {https://uottawa.libguides.com/how_to_use_zotero/install_zotero_browser_connector},
	abstract = {Bite-size search strategies to help you become an expert searcher.},
	language = {en},
	urldate = {2024-08-30},
	author = {Boutet, Mish},
	file = {Snapshot:/home/sspiegel/Zotero/storage/LX6ISY9J/install_zotero_browser_connector.html:text/html},
}

@misc{noauthor_taiwan_2024,
	title = {Taiwan military says {China} lacks ability to invade, but has other options},
	url = {https://www.nbcnews.com/news/world/taiwan-military-says-china-lacks-ability-invade-options-rcna168937},
	abstract = {Though China is not yet “fully” prepared to invade the self-governing island, it is developing new weapons and could board foreign cargo ships, Taiwan’s defense ministry said.},
	language = {en},
	urldate = {2024-08-30},
	journal = {NBC News},
	month = aug,
	year = {2024},
	file = {Snapshot:/home/sspiegel/Zotero/storage/TTU2ST7C/taiwan-military-says-china-lacks-ability-invade-options-rcna168937.html:text/html},
}

@misc{ng_china_nodate,
	title = {China holds military drills around {Taiwan} as 'strong punishment'},
	url = {https://www.bbc.com/news/articles/cqvv29gpqn1o},
	abstract = {The military manoeuvres come three days after William Lai was sworn in as Taiwan's president.},
	language = {en-GB},
	urldate = {2024-08-30},
	author = {Ng, Kelly and Wingfield-Hayes, Rupert},
	file = {Snapshot:/home/sspiegel/Zotero/storage/QS4Z94MU/cqvv29gpqn1o.html:text/html},
}

@misc{noauthor_about_2023,
	title = {About},
	url = {https://www.ncei.noaa.gov/about-us},
	abstract = {Mission NCEI provides environmental data, products, and services covering the depths of the ocean to the surface of the sun to drive resilience, prosperity, and equity for current and future generations. Vision A tenacious and trusted leader in environmental information for a rapidly changing world with a focus on driving lasting good across our partnerships, our economy, around the U.S and the world.},
	language = {en},
	urldate = {2024-09-06},
	journal = {National Centers for Environmental Information (NCEI)},
	month = jan,
	year = {2023},
	file = {Snapshot:/home/sspiegel/Zotero/storage/I58JB6A3/about-us.html:text/html},
}

@misc{noauthor_climate_nodate,
	title = {Climate {Data} {Online} ({CDO}) - {The} {National} {Climatic} {Data} {Center}'s ({NCDC}) {Climate} {Data} {Online} ({CDO}) provides free access to {NCDC}'s archive of historical weather and climate data in addition to station history information. {\textbar} {National} {Climatic} {Data} {Center} ({NCDC})},
	url = {https://www.ncei.noaa.gov/cdo-web/},
	urldate = {2024-09-06},
	file = {Climate Data Online (CDO) - The National Climatic Data Center's (NCDC) Climate Data Online (CDO) provides free access to NCDC's archive of historical weather and climate data in addition to station history information. | National Climatic Data Center (NCDC):/home/sspiegel/Zotero/storage/E2I45BIZ/cdo-web.html:text/html},
}

@misc{us_epa_climate_2016,
	type = {Reports and {Assessments}},
	title = {Climate {Change} {Indicators}: {Weather} and {Climate}},
	shorttitle = {Climate {Change} {Indicators}},
	url = {https://www.epa.gov/climate-indicators/weather-climate},
	abstract = {Weather and Climate},
	language = {en},
	urldate = {2024-09-06},
	author = {US EPA, OAR},
	month = jun,
	year = {2016},
	file = {Snapshot:/home/sspiegel/Zotero/storage/TA4JUNX9/weather-climate.html:text/html},
}

@misc{wang_review_2022,
	title = {A {Review} on {Graph} {Neural} {Network} {Methods} in {Financial} {Applications}},
	url = {http://arxiv.org/abs/2111.15367},
	doi = {10.48550/arXiv.2111.15367},
	abstract = {With multiple components and relations, financial data are often presented as graph data, since it could represent both the individual features and the complicated relations. Due to the complexity and volatility of the financial market, the graph constructed on the financial data is often heterogeneous or time-varying, which imposes challenges on modeling technology. Among the graph modeling technologies, graph neural network (GNN) models are able to handle the complex graph structure and achieve great performance and thus could be used to solve financial tasks. In this work, we provide a comprehensive review of GNN models in recent financial context. We first categorize the commonly-used financial graphs and summarize the feature processing step for each node. Then we summarize the GNN methodology for each graph type, application in each area, and propose some potential research areas.},
	urldate = {2025-09-03},
	publisher = {arXiv},
	author = {Wang, Jianian and Zhang, Sheng and Xiao, Yanghua and Song, Rui},
	month = apr,
	year = {2022},
	note = {arXiv:2111.15367 [q-fin]},
	keywords = {Computer Science - Machine Learning, Quantitative Finance - Statistical Finance, Statistics - Applications},
	file = {Full Text PDF:/home/sspiegel/Zotero/storage/GMD2E7A7/Wang et al. - 2022 - A Review on Graph Neural Network Methods in Financial Applications.pdf:application/pdf;Snapshot:/home/sspiegel/Zotero/storage/4WX6JB24/2111.html:text/html},
}

@misc{kong_generative_2023,
	title = {Generative {Models} for {3D} {Point} {Clouds}},
	url = {http://arxiv.org/abs/2302.13408},
	doi = {10.48550/arXiv.2302.13408},
	abstract = {Point clouds are rich geometric data structures, where their three dimensional structure offers an excellent domain for understanding the representation learning and generative modeling in 3D space. In this work, we aim to improve the performance of point cloud latent-space generative models by experimenting with transformer encoders, latent-space flow models, and autoregressive decoders. We analyze and compare both generation and reconstruction performance of these models on various object types.},
	urldate = {2025-10-11},
	publisher = {arXiv},
	author = {Kong, Lingjie and Rajak, Pankaj and Shakeri, Siamak},
	month = feb,
	year = {2023},
	note = {arXiv:2302.13408 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
	file = {Full Text PDF:/home/sspiegel/Zotero/storage/U3QI4PCX/Kong et al. - 2023 - Generative Models for 3D Point Clouds.pdf:application/pdf;Snapshot:/home/sspiegel/Zotero/storage/DLJKIELP/2302.html:text/html},
}

@misc{kong_generative_2023-1,
	title = {Generative {Models} for {3D} {Point} {Clouds}},
	url = {http://arxiv.org/abs/2302.13408},
	doi = {10.48550/arXiv.2302.13408},
	abstract = {Point clouds are rich geometric data structures, where their three dimensional structure offers an excellent domain for understanding the representation learning and generative modeling in 3D space. In this work, we aim to improve the performance of point cloud latent-space generative models by experimenting with transformer encoders, latent-space flow models, and autoregressive decoders. We analyze and compare both generation and reconstruction performance of these models on various object types.},
	urldate = {2025-10-11},
	publisher = {arXiv},
	author = {Kong, Lingjie and Rajak, Pankaj and Shakeri, Siamak},
	month = feb,
	year = {2023},
	note = {arXiv:2302.13408 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
	file = {Preprint PDF:/home/sspiegel/Zotero/storage/8Q3XRWAK/Kong et al. - 2023 - Generative Models for 3D Point Clouds.pdf:application/pdf;Snapshot:/home/sspiegel/Zotero/storage/CLESAH66/2302.html:text/html},
}

@article{thomas_learning_nodate,
	title = {Learning new representations for {3D} point cloud semantic segmentation},
	language = {en},
	author = {Thomas, Hugues},
	file = {PDF:/home/sspiegel/Zotero/storage/JATS2XGC/Thomas - Learning new representations for 3D point cloud semantic segmentation.pdf:application/pdf},
}

@article{han_whu-urban3d_2024,
	title = {{WHU}-{Urban3D}: {An} urban scene {LiDAR} point cloud dataset for semantic instance segmentation},
	volume = {209},
	issn = {0924-2716},
	shorttitle = {{WHU}-{Urban3D}},
	url = {https://www.sciencedirect.com/science/article/pii/S0924271624000522},
	doi = {10.1016/j.isprsjprs.2024.02.007},
	abstract = {With the rapid advancement of 3D sensors, there is an increasing demand for 3D scene understanding and an increasing number of 3D deep learning algorithms have been proposed. However, a large-scale and richly annotated 3D point cloud dataset is critical to understanding complicated road and urban scenes. Motivated by the need to bridge the gap between the rising demand for 3D urban scene understanding and limited LiDAR point cloud datasets, this paper proposes a richly annotated WHU-Urban3D dataset and an effective method for semantic instance segmentation. WHU-Urban3D stands out from existing datasets due to its distinctive features: (1) extensive coverage of both Airborne Laser Scanning and Mobile Laser Scanning point clouds, along with panoramic images; (2) containing large-scale road and urban scenes in different cities (over 3.2×106m2 area), with richly point-wise semantic instance labels (over 200 million points); (3) inclusion of particular attributes (e.g., reflected intensity, number of returns) in addition to 3D coordinates. This paper also provides the performance of several representative baseline methods and outlines potential future works and challenges for fully exploiting this dataset. The WHU-Urban3D dataset is publicly accessible at https://whu3d.com/.},
	urldate = {2025-10-13},
	journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
	author = {Han, Xu and Liu, Chong and Zhou, Yuzhou and Tan, Kai and Dong, Zhen and Yang, Bisheng},
	month = mar,
	year = {2024},
	keywords = {Machine learning, Point cloud, Semantic instance segmentation, Urban-scale dataset},
	pages = {500--513},
	file = {ScienceDirect Snapshot:/home/sspiegel/Zotero/storage/5WHCA6QZ/S0924271624000522.html:text/html},
}

@article{chakraborty_segmentation_2024,
	title = {Segmentation of {LiDAR} point cloud data in urban areas using adaptive neighborhood selection technique},
	volume = {19},
	issn = {1932-6203},
	url = {https://pmc.ncbi.nlm.nih.gov/articles/PMC11257351/},
	doi = {10.1371/journal.pone.0307138},
	abstract = {Semantic segmentation of urban areas using Light Detection and Ranging (LiDAR) point cloud data is challenging due to the complexity, outliers, and heterogeneous nature of the input point cloud data. The machine learning-based methods for segmenting point clouds suffer from the imprecise computation of the training feature values. The most important factor that influences how precisely the feature values are computed is the neighborhood chosen by each point. This research addresses this issue and proposes a suitable adaptive neighborhood selection approach for individual points by completely considering the complex and heterogeneous nature of the input LiDAR point cloud data. The proposed approach is evaluated on high-density mobile and low-density aerial LiDAR point cloud datasets using the Random Forest machine learning classifier. In the context of performance evaluation, the proposed approach confirms the competitive performance over the state-of-the-art approaches. The computed accuracy and F1-score for the high-density Toronto and low-density Vaihingen datasets are greater than 91\% and 82\%, respectively.},
	number = {7},
	urldate = {2025-10-13},
	journal = {PLOS ONE},
	author = {Chakraborty, Debobrata and Dey, Emon Kumar},
	month = jul,
	year = {2024},
	pmid = {39024214},
	pmcid = {PMC11257351},
	pages = {e0307138},
	file = {Full Text PDF:/home/sspiegel/Zotero/storage/EYATSKS9/Chakraborty and Dey - 2024 - Segmentation of LiDAR point cloud data in urban areas using adaptive neighborhood selection techniqu.pdf:application/pdf},
}

@article{kuprowski_feature_2023,
	title = {Feature {Selection} for {Airbone} {LiDAR} {Point} {Cloud} {Classification}},
	volume = {15},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2072-4292},
	url = {https://www.mdpi.com/2072-4292/15/3/561},
	doi = {10.3390/rs15030561},
	abstract = {The classification of airborne LiDAR data is a prerequisite for many spatial data elaborations and analysis. In the domain of power supply networks, it is of utmost importance to be able to discern at least five classes for further processing—ground, buildings, vegetation, poles, and catenaries. This process is mainly performed manually by domain experts with the use of advanced point cloud manipulation software. The goal of this paper is to find a set of features which would divide space well enough to achieve accurate automatic classification on all relevant classes within the domain, thus reducing manual labor. To tackle this problem, we propose a single multi-class approach to classify all four basic classes (excluding ground) in a power supply domain with single pass-through, using one network. The proposed solution implements random forests and gradient boosting to create a feature-based per-point classifier which achieved an accuracy and F1 score of over 99\% on all tested cases, with the maximum of 99.7\% for accuracy and 99.5\% for F1 score. Moreover, we achieved a maximum of 81.7\% F1 score for the most sparse class. The results show that the proposed set of features for the LiDAR data cloud is effective in power supply line classification.},
	language = {en},
	number = {3},
	urldate = {2025-10-13},
	journal = {Remote Sensing},
	author = {Kuprowski, Mateusz and Drozda, Pawel},
	month = jan,
	year = {2023},
	note = {Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {feature selection, LiDAR, multi-scale neighborhood features, power supply network classification, random forests, XGBoost},
	pages = {561},
	file = {Full Text PDF:/home/sspiegel/Zotero/storage/G8BN6WAV/Kuprowski and Drozda - 2023 - Feature Selection for Airbone LiDAR Point Cloud Classification.pdf:application/pdf},
}

@inproceedings{thomas_semantic_2018,
	address = {Verona},
	title = {Semantic {Classification} of {3D} {Point} {Clouds} with {Multiscale} {Spherical} {Neighborhoods}},
	isbn = {978-1-5386-8425-2},
	url = {https://ieeexplore.ieee.org/document/8490990/},
	doi = {10.1109/3DV.2018.00052},
	abstract = {This paper introduces a new deﬁnition of multiscale neighborhoods in 3D point clouds. This deﬁnition, based on spherical neighborhoods and proportional subsampling, allows the computation of features with a consistent geometrical meaning, which is not the case when using k-nearest neighbors. With an appropriate learning strategy, the proposed features can be used in a random forest to classify 3D points. In this semantic classiﬁcation task, we show that our multiscale features outperform state-of-the-art features using the same experimental conditions. Furthermore, their classiﬁcation power competes with more elaborate classiﬁcation approaches including Deep Learning methods.},
	language = {en},
	urldate = {2025-10-14},
	booktitle = {2018 {International} {Conference} on {3D} {Vision} ({3DV})},
	publisher = {IEEE},
	author = {Thomas, Hugues and Goulette, Francois and Deschaud, Jean-Emmanuel and Marcotegui, Beatriz and LeGall, Yann},
	month = sep,
	year = {2018},
	pages = {390--398},
	file = {PDF:/home/sspiegel/Zotero/storage/2WKC3BHE/Thomas et al. - 2018 - Semantic Classification of 3D Point Clouds with Multiscale Spherical Neighborhoods.pdf:application/pdf},
}

@misc{noauthor_2020_nodate,
	title = {2020 {LiDAR} - {Classified} {LAS}},
	url = {https://opendata.dc.gov/datasets/DCGIS::2020-lidar-classified-las/about},
	abstract = {This data is used for the planning and management of Washington, D.C. by local government agencies.},
	language = {en-us},
	urldate = {2025-10-17},
	file = {Snapshot:/home/sspiegel/Zotero/storage/ZS67RP74/about.html:text/html},
}

@misc{noauthor_kpconv_nodate,
	title = {{KPConv}: {Flexible} and {Deformable} {Convolution} for {Point} {Clouds}},
	shorttitle = {{KPConv}},
	url = {https://ar5iv.labs.arxiv.org/html/1904.08889},
	abstract = {We present Kernel Point Convolution111Project page: https://github.com/HuguesTHOMAS/KPConv (KPConv), a new design of point convolution, i.e. that operates on point clouds without any intermediate representation. The co…},
	language = {en},
	urldate = {2025-10-22},
	journal = {ar5iv},
	file = {Snapshot:/home/sspiegel/Zotero/storage/DIIHWCYN/1904.html:text/html},
}

@article{rusu_semantic_2010,
	title = {Semantic {3D} {Object} {Maps} for {Everyday} {Manipulation} in {Human} {Living} {Environments}},
	volume = {24},
	issn = {1610-1987},
	url = {https://doi.org/10.1007/s13218-010-0059-6},
	doi = {10.1007/s13218-010-0059-6},
	abstract = {Environment models serve as important resources for an autonomous robot by providing it with the necessary task-relevant information about its habitat. Their use enables robots to perform their tasks more reliably, flexibly, and efficiently. As autonomous robotic platforms get more sophisticated manipulation capabilities, they also need more expressive and comprehensive environment models: for manipulation purposes their models have to include the objects present in the world, together with their position, form, and other aspects, as well as an interpretation of these objects with respect to the robot tasks.},
	language = {en},
	number = {4},
	urldate = {2025-10-24},
	journal = {KI - Künstliche Intelligenz},
	author = {Rusu, Radu Bogdan},
	month = nov,
	year = {2010},
	keywords = {Machine Learning Classifier, Perception Problem, Point Cloud, Robot Hexapod, Robot Operating System},
	pages = {345--348},
}

@inproceedings{tan_toronto-3d_2020,
	address = {Seattle, WA, USA},
	title = {Toronto-{3D}: {A} {Large}-scale {Mobile} {LiDAR} {Dataset} for {Semantic} {Segmentation} of {Urban} {Roadways}},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	isbn = {978-1-7281-9360-1},
	shorttitle = {Toronto-{3D}},
	url = {https://ieeexplore.ieee.org/document/9150609/},
	doi = {10.1109/CVPRW50498.2020.00109},
	abstract = {Semantic segmentation of large-scale outdoor point clouds is essential for urban scene understanding in various applications, especially autonomous driving and urban high-deﬁnition (HD) mapping. With rapid developments of mobile laser scanning (MLS) systems, massive point clouds are available for scene understanding, but publicly accessible large-scale labeled datasets, which are essential for developing learning-based methods, are still limited. This paper introduces Toronto-3D, a large-scale urban outdoor point cloud dataset acquired by a MLS system in Toronto, Canada for semantic segmentation. This dataset covers approximately 1 km of point clouds and consists of about 78.3 million points with 8 labeled object classes. Baseline experiments for semantic segmentation were conducted and the results conﬁrmed the capability of this dataset to train deep learning models effectively. Toronto-3D is released 1 to encourage new research, and the labels will be improved and updated with feedback from the research community.},
	language = {en},
	urldate = {2025-10-24},
	booktitle = {2020 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} {Workshops} ({CVPRW})},
	publisher = {IEEE},
	author = {Tan, Weikai and Qin, Nannan and Ma, Lingfei and Li, Ying and Du, Jing and Cai, Guorong and Yang, Ke and Li, Jonathan},
	month = jun,
	year = {2020},
	pages = {797--806},
	file = {PDF:/home/sspiegel/Zotero/storage/DEYM2XCJ/Tan et al. - 2020 - Toronto-3D A Large-scale Mobile LiDAR Dataset for Semantic Segmentation of Urban Roadways.pdf:application/pdf},
}

@misc{noauthor_illinois_nodate,
	title = {Illinois {Height} {Modernization} ({ILHMP}): {LiDAR} {Data} {\textbar} clearinghouse.isgs.illinois.edu},
	url = {https://clearinghouse.isgs.illinois.edu/data/elevation/illinois-height-modernization-ilhmp},
	urldate = {2025-10-24},
	file = {Illinois Height Modernization (ILHMP)\: LiDAR Data | clearinghouse.isgs.illinois.edu:/home/sspiegel/Zotero/storage/J95SIXG3/illinois-height-modernization-ilhmp.html:text/html},
}
